# -*- coding: utf-8 -*-
"""FaceMask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1akwYgV1YqCKxb4zZxpyswFB70-Z_fF4X
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

import kagglehub
path = kagglehub.dataset_download('andrewmvd/face-mask-detection')
print("Dataset path:", path)


import os
import cv2
import xml.etree.ElementTree as ET
import numpy as np
import tensorflow as tf
from tensorflow.keras import mixed_precision
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split
#import tensorflow_addons as tfa

mixed_precision.set_global_policy('mixed_float16')

# --- Constants ---
IMG_SIZE   = 256
BATCH_SIZE = 32
AUTOTUNE   = tf.data.AUTOTUNE
LABEL_MAP  = {"with_mask":0, "without_mask":1, "mask_weared_incorrect":2}
NUM_CLASSES = len(LABEL_MAP)
MIN_SIZE_FRAC = 0.02   # drop boxes smaller than 2% of image size

def parse_annotation(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()
    boxes, labels = [], []
    for obj in root.findall('object'):
        label = obj.find('name').text
        bbox  = obj.find('bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        boxes.append([xmin, ymin, xmax, ymax])
        labels.append(LABEL_MAP[label])
    return boxes, labels

images_dir      = os.path.join(path, 'images')
annotations_dir = os.path.join(path, 'annotations')
paths, labels, bboxes = [], [], []

for xml_fname in os.listdir(annotations_dir):
    if not xml_fname.endswith('.xml'): continue
    xml_path = os.path.join(annotations_dir, xml_fname)
    boxes, labs = parse_annotation(xml_path)
    img_path = os.path.join(images_dir, xml_fname.replace('.xml', '.png'))
    img = cv2.imread(img_path)
    if img is None: continue
    h, w, _ = img.shape
    min_w   = int(MIN_SIZE_FRAC * w)
    min_h   = int(MIN_SIZE_FRAC * h)
    for (xmin, ymin, xmax, ymax), lab in zip(boxes, labs):
      if (xmax - xmin) >= min_w and (ymax - ymin) >= min_h:
        paths.append(img_path)
        labels.append(lab)
        bboxes.append([xmin, ymin, xmax, ymax])


train_paths, val_paths, train_labels, val_labels, train_bboxes, val_bboxes = train_test_split(
    paths, labels, bboxes, test_size=0.2, random_state=69, stratify=labels
)


def augment_image(image):
    # Random horizontal flip
    image = tf.image.random_flip_left_right(image)

    # Random brightness (mild)
    image = tf.image.random_brightness(image, max_delta=0.1)

    # Random contrast
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)

    # Random hue (very slight shift)
    image = tf.image.random_hue(image, max_delta=0.02)

    # Random saturation
    image = tf.image.random_saturation(image, lower=0.9, upper=1.1)

    # Simulate blur using average pooling (acts like blur when down & upsampled)
    def apply_blur(img):
        return tf.nn.avg_pool2d(tf.expand_dims(img, 0), ksize=3, strides=1, padding='SAME')[0]

    if tf.random.uniform(()) > 0.7:
        image = apply_blur(image)

    # Cutout: erase a small patch
    # def cutout(img, mask_size=40):
    #   height, width, _ = img.shape
    #   cutout_center_height = tf.random.uniform([], 0, height, dtype=tf.int32)
    #   cutout_center_width  = tf.random.uniform([], 0, width, dtype=tf.int32)

    #   lower_pad = tf.maximum(0, cutout_center_height - mask_size // 2)
    #   upper_pad = tf.maximum(0, height - cutout_center_height - mask_size // 2)
    #   left_pad  = tf.maximum(0, cutout_center_width - mask_size // 2)
    #   right_pad = tf.maximum(0, width - cutout_center_width - mask_size // 2)

    #   cutout_shape = [height - (lower_pad + upper_pad), width - (left_pad + right_pad), 3]
    #   padding_dims = [[lower_pad, upper_pad], [left_pad, right_pad], [0, 0]]

    #   mask = tf.pad(tf.zeros(cutout_shape, dtype=img.dtype), padding_dims, constant_values=1)
    #   return img * mask


    # if tf.random.uniform(()) > 0.8:
    #       image = cutout(image)

    return image


def decode_crop_resize(path, label, bbox):
    image = tf.io.read_file(path)
    image = tf.image.decode_png(image, channels=3)

    img_shape = tf.shape(image)
    img_height = img_shape[0]
    img_width  = img_shape[1]

    xmin, ymin, xmax, ymax = tf.unstack(tf.cast(bbox, tf.int32))
    xmin = tf.clip_by_value(xmin, 0, img_width  - 1)
    xmax = tf.clip_by_value(xmax, 0, img_width  - 1)
    ymin = tf.clip_by_value(ymin, 0, img_height - 1)
    ymax = tf.clip_by_value(ymax, 0, img_height - 1)

    width  = tf.maximum(xmax - xmin, 1)
    height = tf.maximum(ymax - ymin, 1)

    cropped_image = tf.image.crop_to_bounding_box(image, ymin, xmin, height , width)
    resized_image = tf.image.resize(cropped_image, [IMG_SIZE, IMG_SIZE])
    processed_image = preprocess_input(resized_image)

    if tf.random.uniform([]) > 0.5:
         processed_image=augment_image(processed_image)

    return processed_image, tf.one_hot(label, NUM_CLASSES)


def prepare_dataset(paths, labels, bboxes, is_training=True):
    base_ds = tf.data.Dataset.from_tensor_slices((paths, labels, bboxes))

    def map_fn(path, label, bbox):
        return decode_crop_resize(path, label, bbox)

    # Standard dataset
    dataset = base_ds.map(map_fn, num_parallel_calls=AUTOTUNE)



    # Oversample only "mask_weared_incorrect" (label == 2)
    if is_training:
        mask_incorrect_ds = base_ds.filter(lambda p, l, b: tf.equal(l, 2))
        # Apply extra augmentation multiple times
        num_dupes = 3  # Adjust this for how much oversampling you want
        for _ in range(num_dupes):
            augmented = mask_incorrect_ds.map(map_fn, num_parallel_calls=AUTOTUNE)
            dataset = dataset.concatenate(augmented)
        dataset = dataset.shuffle(buffer_size=1000)
        dataset = dataset.repeat()
    return dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)


train_ds = prepare_dataset(train_paths, train_labels, train_bboxes, is_training=True)
val_ds = prepare_dataset(val_paths, val_labels, val_bboxes, is_training=False)

from collections import Counter
print(Counter(train_labels))

print("→ raw train_paths:", len(train_paths))
print("→ after map+filter cardinality:",
      tf.data.experimental.cardinality(train_ds).numpy())

base_model = MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights='imagenet'
)

base_model.trainable = False


inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.1)(x)
# Ensure output is float32 (to match loss)
outputs = Dense(NUM_CLASSES, activation='softmax', dtype='float32')(x)
model = Model(inputs, outputs)

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=1e-4,
    decay_steps=1000,
    decay_rate=0.96,
    staircase=True
)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),
    metrics=['accuracy']
)
model.summary()

from tensorflow.keras.callbacks import Callback, ModelCheckpoint
from sklearn.metrics import f1_score,accuracy_score, classification_report
from sklearn.utils import class_weight

class F1EarlyStopping(Callback):
    def __init__(self, val_data, patience=5, delta=0.005, acc_delta=0.01, save_path=None):
        super(F1EarlyStopping, self).__init__()
        self.val_data = val_data
        self.patience = patience
        self.delta = delta  # how much drop in F1 is tolerated
        self.acc_delta = acc_delta  # how much val_acc increase is significant
        self.save_path = save_path

        self.best = -np.inf
        self.best_acc = -np.inf
        self.wait = 0

    def on_epoch_end(self, epoch, logs=None):
        val_pred = []
        val_true = []
        for batch in self.val_data:
            x, y = batch
            preds = self.model.predict(x, verbose=0)
            val_pred.extend(np.argmax(preds, axis=1))
            val_true.extend(np.argmax(y.numpy(), axis=1))

        f1 = f1_score(val_true, val_pred, average='macro')
        val_acc = accuracy_score(val_true, val_pred)

        print(f"\nEpoch {epoch+1} F1 Score: {f1:.4f}, Val Acc: {val_acc:.4f}")

        should_save = (
            f1 > self.best
            or (f1 == self.best and val_acc > self.best_acc)
            or (val_acc > (self.best_acc + self.acc_delta) and (self.best - f1) <= self.delta)
        )

        if should_save:
            print("Validation F1 improved or acceptable trade-off; saving model.")
            if self.save_path:
                self.model.save(self.save_path)
            self.best = max(self.best, f1)
            self.best_acc = max(self.best_acc, val_acc)
            self.wait = 0
        else:
            self.wait += 1
            print(f"No significant F1 improvement for {self.wait} epochs.")
            if self.wait >= self.patience:
                print("Early stopping triggered.")
                self.model.stop_training = True

from google.colab import drive
drive.mount('/content/drive')

SavePath='/content/drive/MyDrive/best_modelV2d.keras'
checkpoint_cb = ModelCheckpoint(
    SavePath,
    monitor='val_accuracy', save_best_only=True, verbose=1
)
# earlystop_cb = EarlyStopping(
#     monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1
# )

earlystop_f1_cb = F1EarlyStopping(val_ds, patience=9, save_path=SavePath)

import datetime

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

from sklearn.utils import class_weight
import numpy as np

# class_weights = class_weight.compute_class_weight(
#     class_weight='balanced',
#     classes=np.unique(train_labels),
#     y=train_labels
# )
# class_weights = dict(enumerate(class_weights))
post_counts = {
    0: 2585,
    1: 574,
    2: 98 * 4   # original + 3 duplicates
}
total = sum(post_counts.values())
class_weights = {cls: total/(NUM_CLASSES * cnt)
      for cls, cnt in post_counts.items()}

import math

# Count your original positives + oversampled copies:
N_base        = len(train_paths)                              # ≈ 3257
mask2_count   = sum(1 for l in train_labels if l == 2)        # how many “mask_weared_incorrect”
num_dupes     = 3
N_total       = N_base + num_dupes * mask2_count              # after oversampling
steps_per_ep  = math.ceil(N_total / BATCH_SIZE)


# history = model.fit(
#     train_ds,
#     validation_data=val_ds,
#     epochs=45,
#     steps_per_epoch=steps_per_ep,
#     class_weight=class_weights,
#     callbacks=[earlystop_f1_cb,tensorboard_cb]
# )

model.load_weights(SavePath)
history = model.fit(
     train_ds,
     validation_data=val_ds,
     epochs=45,
     steps_per_epoch=steps_per_ep,
     class_weight=class_weights,
     callbacks=[earlystop_f1_cb,tensorboard_cb]
 )

base_model.trainable = True
for layer in base_model.layers[:-30]:
    layer.trainable = False
model.summary(show_trainable=True)

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05),
    metrics=['accuracy']
)

history_further = model.fit(
    train_ds,
    validation_data=val_ds,
    initial_epoch = len(history.history['loss']),
    epochs=65,
    steps_per_epoch=steps_per_ep,
    class_weight=class_weights,
    callbacks=[earlystop_f1_cb,tensorboard_cb]
)

# from google.colab import drive
# import tensorflow as tf

# # Mount Google Drive
# drive.mount('/content/drive')

# # Path to the saved model
# model_path = '/content/drive/MyDrive/best_modelV2c.keras'  # Replace this with your model path

# # Load the saved model
# model = tf.keras.models.load_model(model_path)

# # Check model summary to verify it's loaded correctly
# model.summary()

model.load_weights(SavePath)

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Collect all true labels and predictions
true_labels = []
pred_labels = []

for images, labels in val_ds:
    preds = model.predict(images, verbose=0)
    true_labels.extend(np.argmax(labels.numpy(), axis=1))
    pred_labels.extend(np.argmax(preds, axis=1))

cm = confusion_matrix(true_labels, pred_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=LABEL_MAP.keys())

# Plot
plt.figure(figsize=(6, 6))
disp.plot(cmap='Blues', values_format='d')
plt.title("Confusion Matrix on Validation Set")
plt.show()
plt.tight_layout()

# Combine histories
def combine_histories(h1, h2):
    combined = {}
    for key in h1.history:
        combined[key] = h1.history[key] + h2.history.get(key, [])
    return combined

full_history = combine_histories(history, history_further)

N = len(full_history["loss"])  # or set this to EPOCHS
plt.style.use("ggplot")
plt.figure()
plt.plot(np.arange(0, N), full_history["loss"], label="train_loss")
plt.plot(np.arange(0, N), full_history["val_loss"], label="val_loss")
plt.plot(np.arange(0, N), full_history["accuracy"], label="train_acc")
plt.plot(np.arange(0, N), full_history["val_accuracy"], label="val_acc")
plt.title("Training Loss and Accuracy")
plt.xlabel("Epoch #")
plt.ylabel("Loss/Accuracy")
plt.legend(loc="lower left")
#plt.savefig("training_plot.png")  # save to file
plt.show()  # also display

print("Classification Report:\n")
print(classification_report(true_labels, pred_labels, target_names=LABEL_MAP.keys()))